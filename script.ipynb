{"cells":[{"cell_type":"markdown","source":["Author Yizhou Li, e-mail: lyzpp2000@163.com"],"metadata":{}},{"cell_type":"markdown","source":["Problem Statement:"],"metadata":{}},{"cell_type":"markdown","source":["Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling<br>\n","or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences<br>\n","price negotiations than the number of bedrooms or a white-picket fence.<br>\n","<br>\n","With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition<br>\n","challenges you to predict the final price of each home."],"metadata":{}},{"cell_type":"markdown","source":["# 1. Data Preprocessing"],"metadata":{}},{"cell_type":"code","execution_count":25,"source":["# Loading necessary libraries and datasets.\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.compose import make_column_transformer\n","from sklearn.compose import make_column_selector\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LinearRegression, Lasso, Ridge\n","\n","# Functions definitions.\n","# def load_data():\n","#     train_df = pd.read_csv(\"input/train.csv\")\n","#     test_df = pd.read_csv(\"input/test.csv\")\n","#     my_df = train_df.merge(test_df, how='outer')\n","#     return my_df\n","\n","def drop_duplicates(my_df):\n","    my_df.drop_duplicates(inplace=True)\n","    my_df = my_df.loc[:,~my_df.columns.duplicated()]\n","    return my_df\n","\n","def make_mi_scores(X, y):\n","    X = X.copy()\n","    for colname in X.select_dtypes([\"object\", \"category\"]):\n","        X[colname], _ = X[colname].factorize()\n","    # All discrete features should now have integer dtypes\n","    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n","    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n","    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n","    mi_scores = mi_scores.sort_values(ascending=False)\n","    return mi_scores\n","\n","def plot_mi_scores(scores):\n","    scores = scores.sort_values(ascending=True)\n","    width = np.arange(len(scores))\n","    ticks = list(scores.index)\n","    plt.barh(width, scores)\n","    plt.yticks(width, ticks)\n","    plt.title(\"Mutual Information Scores\")\n","\n","def drop_columns_missing_above_80_percent(train_df, test_df) -> None :\n","    null_series = train_df.isnull().sum().sort_values(ascending=False)\n","    print(\"columns have null values:\\n\", null_series, \"\\n\", sep=\"\")\n","    temp_lst = []\n","    for i,v in null_series.items():\n","        if v / train_df.shape[0] >= 0.8:\n","            temp_lst.append(i)\n","    train_df.drop(temp_lst, axis=1, inplace=True)\n","    null_series = train_df.isnull().sum().sort_values(ascending=False)\n","    print(\"after we drop the columns that miss 80 percent values:\\n\", null_series, sep=\"\")\n","\n","    null_series = test_df.isnull().sum().sort_values(ascending=False)\n","    print(\"columns have null values:\\n\", null_series, \"\\n\", sep=\"\")\n","    temp_lst = []\n","    for i,v in null_series.items():\n","        if v / test_df.shape[0] >= 0.8:\n","            temp_lst.append(i)\n","    test_df.drop(temp_lst, axis=1, inplace=True)\n","    null_series = test_df.isnull().sum().sort_values(ascending=False)\n","    print(\"after we drop the columns that miss 80 percent values:\\n\", null_series, sep=\"\")\n","\n","# Load Data.\n","train_df = pd.read_csv(\"input/train.csv\")\n","test_df = pd.read_csv(\"input/test.csv\")\n","# my_df = train_df.merge(test_df, how='outer')\n","\n","# Sol1\n","# Drop duplicates.\n","# train_df = drop_duplicates(train_df)\n","# test_df = drop_duplicates(test_df)\n","\n","# example of using the ColumnTransformer for the Abalone dataset\n","from numpy import mean, mean, std\n","from pandas import read_csv\n","from sklearn.model_selection import cross_val_score, KFold\n","from sklearn.compose import ColumnTransformer, make_column_selector as selector\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.svm import SVR\n","from sklearn.pipeline import Pipeline\n","\n","# Sol2\n","# split into inputs and outputs\n","# last_ix = len(train_df.columns) - 1\n","# sale_price_column = train_df.iloc[:,last_ix]\n","# X, y = train_df.drop(columns=[\"SalePrice\"], axis=1), sale_price_column\n","# print(X.shape, y.shape)\n","# # url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n","# # dataframe = read_csv(url, header=None)\n","# # print(train_df.info())\n","# # split into inputs and outputs\n","# # last_ix = len(dataframe.columns) - 1\n","# # X, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n","# # determine categorical and numerical features\n","# numerical_ix = X.select_dtypes(include=['int64', 'float64']).columns\n","# categorical_ix = X.select_dtypes(include=['object', 'bool']).columns\n","# # define the data preparation for the columns\n","# # t = [('cat', OneHotEncoder(), categorical_ix), ('num', MinMaxScaler(), numerical_ix)]\n","# t = [('imputer_cat', SimpleImputer(strategy='most_frequent'), categorical_ix)\n","# , ('imputer_num', SimpleImputer(strategy='mean'), numerical_ix)\n","# , ('encoder', OneHotEncoder(), categorical_ix)]\n","# col_transform = ColumnTransformer(transformers=t, remainder=\"passthrough\")\n","# print(col_transform.fit_transform(X))\n","# define the model\n","# model = SVR(kernel='rbf',gamma='scale',C=100)\n","# # define the data preparation and modeling pipeline\n","# pipeline = Pipeline(steps=[('prep',col_transform), ('m', model)])\n","# # define the model cross-validation configuration\n","# cv = KFold(n_splits=10, shuffle=True, random_state=1)\n","# # evaluate the pipeline using cross validation and calculate MAE\n","# scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n","# # convert MAE scores to positive values\n","# scores = absolute(scores)\n","# # summarize the model performance\n","# print('MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n","\n","last_ix = len(train_df.columns) - 1\n","sale_price_column = train_df.iloc[:,last_ix]\n","X_train, y_train = train_df.drop(columns=[\"SalePrice\"], axis=1), sale_price_column\n","\n","numerical_ix = train_df.select_dtypes(include=['int64', 'float64']).columns\n","categorical_ix = train_df.select_dtypes(include=['object', 'bool']).columns\n","\n","# numeric_features = ['Salary']\n","numeric_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median'))])\n","    # ('scaler', StandardScaler())])\n","\n","# categorical_features = ['Age','Country']\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, selector(dtype_include=\"number\")),\n","        ('cat', categorical_transformer, selector(dtype_include=\"object\"))])\n","\n","rgr = Pipeline(steps=[('preprocessor', preprocessor),\n","                  ('regressor', LinearRegression())]).fit(X_train, y_train)\n","\n","rgr.predict(test_df)\n"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([108423.75473562, 147228.28376822, 182325.61016666, ...,\n","       171388.82188759, 112851.62790252, 228938.64235655])"]},"metadata":{},"execution_count":25}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["fig, axs = plt.subplots(30, 3)\n","my_lst = [col for col in train_df.columns]\n","fig.set_size_inches(25, 200)\n","row = 30\n","col = 3\n","y = train_df[\"SalePrice\"]\n","for i in range(row):\n","    for j in range(col):\n","        if len(my_lst) == 0:\n","            break\n","        x = train_df[my_lst.pop()]\n","        axs[i, j].scatter(x, y)\n","        axs[i, j].set_xlabel(x.name)\n","        axs[i, j].set_ylabel(\"SalePrice\")\n","        axs[i, j].set_title(x.name + \" vs SalePrice\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["x_data = train_df[['LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea',\n","                    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n","                    'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n","                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]\n","y_data = train_df[\"SalePrice\"]\n","# my_train_lst = [col for col in train_df.columns]\n","# my_test_lst = [col for col in test_df.columns]\n","# my_train_lst.pop()\n","# my_test_lst.pop()\n","\n","# x_data = train_df[my_train_lst]\n","# test_data = test_df[my_test_lst]\n","test_data = test_df[ ['LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea',\n","                    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n","                    'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n","                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]\n","x_train, x_test, y_train, y_test = train_test_split(x_data, y_data)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# 5. Models building, evaluation, and predicting\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model = LinearRegression()\n","model2 = Lasso()\n","model3 = Ridge()\n","model4 = DecisionTreeRegressor()\n","model5 = RandomForestRegressor()\n","\n","model.fit(X=x_train, y=y_train)\n","model2.fit(X=x_train, y=y_train)\n","model3.fit(X=x_train, y=y_train)\n","model4.fit(X=x_train, y=y_train)\n","model5.fit(X=x_train, y=y_train)\n","\n","print(\"the accuracy score using with LinearRegression() model \", model.score(x_test, y_test))\n","print(\"the accuracy score using with Lasso() model \", model2.score(x_test, y_test))\n","print(\"the accuracy score using with Ridge() model \", model3.score(x_test, y_test))\n","print(\"the accuracy score using with DecisionTreeRegressor() model \", model4.score(x_test, y_test))\n","print(\"the accuracy score using with RandomForestRegressor() model \", model5.score(x_test, y_test))\n","\n","model.fit(X=x_train, y=y_train)\n","result = model.predict(test_data)\n","temp = test_df\n","temp.reset_index(inplace=True)\n","metric = pd.Series(result, name = 'SalePrice')\n","final_metric = pd.concat([temp[\"Id\"], metric], axis = 1)\n","final_metric.to_csv(\"submission.csv\",index =False)"],"outputs":[{"output_type":"stream","name":"stdout","text":["the accuracy score using with LinearRegression() model  0.699274404306837\n","the accuracy score using with Lasso() model  0.699255842859624\n","the accuracy score using with Ridge() model  0.6988298969020352\n","the accuracy score using with DecisionTreeRegressor() model  0.5258261751040558\n","the accuracy score using with RandomForestRegressor() model  0.647976119535729\n"]},{"output_type":"error","ename":"ValueError","evalue":"cannot insert level_0, already exists","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-39fc34f37b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfinal_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   5014\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5015\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5016\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5018\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3762\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3763\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"interpreter":{"hash":"470137a20ee2b1e4fecb351c4db86cc479a0f7d2037ff8b0353414b93267fdda"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}