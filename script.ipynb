{"cells":[{"cell_type":"markdown","source":["Author Yizhou Li, e-mail: lyzpp2000@163.com"],"metadata":{}},{"cell_type":"markdown","source":["Problem Statement:"],"metadata":{}},{"cell_type":"markdown","source":["Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling<br>\n","or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences<br>\n","price negotiations than the number of bedrooms or a white-picket fence.<br>\n","<br>\n","With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition<br>\n","challenges you to predict the final price of each home."],"metadata":{}},{"cell_type":"markdown","source":["# 1. Data Preprocessing"],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["# Step1: Loading necessary libraries and datasets.\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","\n","my_df = load_data()\n","\n","# Step2: Functions definitions.\n","def load_data():\n","    train_df = pd.read_csv(\"input/train.csv\")\n","    test_df = pd.read_csv(\"input/test.csv\")\n","    my_df = train_df.merge(test_df, how='outer')\n","    return my_df\n","\n","def drop_duplicates(my_df):\n","    my_df.drop_duplicates(inplace=True)\n","    my_df = my_df.loc[:,~my_df.columns.duplicated()]\n","    return my_df\n","\n","def make_mi_scores(X, y):\n","    X = X.copy()\n","    for colname in X.select_dtypes([\"object\", \"category\"]):\n","        X[colname], _ = X[colname].factorize()\n","    # All discrete features should now have integer dtypes\n","    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n","    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n","    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n","    mi_scores = mi_scores.sort_values(ascending=False)\n","    return mi_scores\n","\n","def plot_mi_scores(scores):\n","    scores = scores.sort_values(ascending=True)\n","    width = np.arange(len(scores))\n","    ticks = list(scores.index)\n","    plt.barh(width, scores)\n","    plt.yticks(width, ticks)\n","    plt.title(\"Mutual Information Scores\")\n","\n","def load_data():\n","    file_path = \"input/house-prices-advanced-regression-techniques/\"\n","    train_df = pd.read_csv(file_path + \"train.csv\", index_col='Id')\n","    test_df = pd.read_csv(file_path + \"test.csv\", index_col='Id')    \n","    print(train_df.head(), \"\\n\")\n","    print(train_df.info(), \"\\n\")\n","\n","    return train_df, test_df\n","\n","def drop_columns_missing_above_80_percent(train_df, test_df) -> None :\n","    null_series = train_df.isnull().sum().sort_values(ascending=False)\n","    print(\"columns have null values:\\n\", null_series, \"\\n\", sep=\"\")\n","    temp_lst = []\n","    for i,v in null_series.items():\n","        if v / train_df.shape[0] >= 0.8:\n","            temp_lst.append(i)\n","    train_df.drop(temp_lst, axis=1, inplace=True)\n","    null_series = train_df.isnull().sum().sort_values(ascending=False)\n","    print(\"after we drop the columns that miss 80 percent values:\\n\", null_series, sep=\"\")\n","\n","    null_series = test_df.isnull().sum().sort_values(ascending=False)\n","    print(\"columns have null values:\\n\", null_series, \"\\n\", sep=\"\")\n","    temp_lst = []\n","    for i,v in null_series.items():\n","        if v / test_df.shape[0] >= 0.8:\n","            temp_lst.append(i)\n","    test_df.drop(temp_lst, axis=1, inplace=True)\n","    null_series = test_df.isnull().sum().sort_values(ascending=False)\n","    print(\"after we drop the columns that miss 80 percent values:\\n\", null_series, sep=\"\")\n","\n","def fill_na(train_df, test_df) -> None :\n","    for i, l in train_df.iteritems():\n","        if l.dtype == \"object\":\n","            l.fillna(value=\"Na\", inplace=True)\n","        else:\n","            l.fillna(value=l.mean(), inplace=True)\n","    for i, l in test_df.iteritems():\n","        if l.dtype == \"object\":\n","            l.fillna(value=\"Na\", inplace=True)\n","        else:\n","            l.fillna(value=l.mean(), inplace=True)\n","\n","# Step3: Drop duplicate indexs and columns, and handle missing values.\n","my_df = drop_duplicates(my_df)\n","# todo simpleimputer\n","\n","# print(train_df.head())\n","# print(train_df.info())\n","# print(test_df.head())\n","# print(test_df.info())\n","\n","# Step4: Encode categorical values into numerical type.\n","\n","# Step5: Split dataset into training and testing sets.\n","\n","# Step6: Feature scaling (Optional)."],"outputs":[{"output_type":"stream","name":"stdout","text":["        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n","1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n","2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n","3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n","4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n","...    ...         ...      ...          ...      ...    ...   ...      ...   \n","2914  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n","2915  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n","2916  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n","2917  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n","2918  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n","\n","     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n","0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","...          ...       ...  ...      ...    ...    ...         ...     ...   \n","2914         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","2915         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","2916         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","2917         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n","2918         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","\n","     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n","0         2   2008        WD         Normal   208500.0  \n","1         5   2007        WD         Normal   181500.0  \n","2         9   2008        WD         Normal   223500.0  \n","3         2   2006        WD        Abnorml   140000.0  \n","4        12   2008        WD         Normal   250000.0  \n","...     ...    ...       ...            ...        ...  \n","2914      6   2006        WD         Normal        NaN  \n","2915      4   2006        WD        Abnorml        NaN  \n","2916      9   2006        WD        Abnorml        NaN  \n","2917      7   2006        WD         Normal        NaN  \n","2918     11   2006        WD         Normal        NaN  \n","\n","[2919 rows x 81 columns]\n"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["fig, axs = plt.subplots(30, 3)\n","my_lst = [col for col in train_df.columns]\n","fig.set_size_inches(25, 200)\n","row = 30\n","col = 3\n","y = train_df[\"SalePrice\"]\n","for i in range(row):\n","    for j in range(col):\n","        if len(my_lst) == 0:\n","            break\n","        x = train_df[my_lst.pop()]\n","        axs[i, j].scatter(x, y)\n","        axs[i, j].set_xlabel(x.name)\n","        axs[i, j].set_ylabel(\"SalePrice\")\n","        axs[i, j].set_title(x.name + \" vs SalePrice\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":60,"source":["x_data = train_df[['LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea',\n","                    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n","                    'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n","                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]\n","y_data = train_df[\"SalePrice\"]\n","# my_train_lst = [col for col in train_df.columns]\n","# my_test_lst = [col for col in test_df.columns]\n","# my_train_lst.pop()\n","# my_test_lst.pop()\n","\n","# x_data = train_df[my_train_lst]\n","# test_data = test_df[my_test_lst]\n","test_data = test_df[ ['LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea',\n","                    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n","                    'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n","                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]\n","x_train, x_test, y_train, y_test = train_test_split(x_data, y_data)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# 5. Models building, evaluation, and predicting\n"],"metadata":{}},{"cell_type":"code","execution_count":61,"source":["model = LinearRegression()\n","model2 = Lasso()\n","model3 = Ridge()\n","model4 = DecisionTreeRegressor()\n","model5 = RandomForestRegressor()\n","\n","model.fit(X=x_train, y=y_train)\n","model2.fit(X=x_train, y=y_train)\n","model3.fit(X=x_train, y=y_train)\n","model4.fit(X=x_train, y=y_train)\n","model5.fit(X=x_train, y=y_train)\n","\n","print(\"the accuracy score using with LinearRegression() model \", model.score(x_test, y_test))\n","print(\"the accuracy score using with Lasso() model \", model2.score(x_test, y_test))\n","print(\"the accuracy score using with Ridge() model \", model3.score(x_test, y_test))\n","print(\"the accuracy score using with DecisionTreeRegressor() model \", model4.score(x_test, y_test))\n","print(\"the accuracy score using with RandomForestRegressor() model \", model5.score(x_test, y_test))\n","\n","model.fit(X=x_train, y=y_train)\n","result = model.predict(test_data)\n","temp = test_df\n","temp.reset_index(inplace=True)\n","metric = pd.Series(result, name = 'SalePrice')\n","final_metric = pd.concat([temp[\"Id\"], metric], axis = 1)\n","final_metric.to_csv(\"submission.csv\",index =False)"],"outputs":[{"output_type":"stream","name":"stdout","text":["the accuracy score using with LinearRegression() model  0.699274404306837\n","the accuracy score using with Lasso() model  0.699255842859624\n","the accuracy score using with Ridge() model  0.6988298969020352\n","the accuracy score using with DecisionTreeRegressor() model  0.5258261751040558\n","the accuracy score using with RandomForestRegressor() model  0.647976119535729\n"]},{"output_type":"error","ename":"ValueError","evalue":"cannot insert level_0, already exists","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-39fc34f37b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfinal_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   5014\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5015\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5016\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5018\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3762\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3763\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"interpreter":{"hash":"470137a20ee2b1e4fecb351c4db86cc479a0f7d2037ff8b0353414b93267fdda"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}