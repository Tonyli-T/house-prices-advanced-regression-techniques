{"cells":[{"cell_type":"markdown","source":["Author Yizhou Li, e-mail: lyzpp2000@163.com"],"metadata":{}},{"cell_type":"markdown","source":["Problem Statement:"],"metadata":{}},{"cell_type":"markdown","source":["Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling<br>\n","or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences<br>\n","price negotiations than the number of bedrooms or a white-picket fence.<br>\n","<br>\n","With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition<br>\n","challenges you to predict the final price of each home."],"metadata":{}},{"cell_type":"markdown","source":["# 1. Data Preprocessing"],"metadata":{}},{"cell_type":"code","execution_count":17,"source":["# Loading necessary libraries and datasets.\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.compose import make_column_transformer\n","from sklearn.compose import make_column_selector\n","from sklearn.impute import SimpleImputer\n","\n","# Functions definitions.\n","# def load_data():\n","#     train_df = pd.read_csv(\"input/train.csv\")\n","#     test_df = pd.read_csv(\"input/test.csv\")\n","#     my_df = train_df.merge(test_df, how='outer')\n","#     return my_df\n","\n","def drop_duplicates(my_df):\n","    my_df.drop_duplicates(inplace=True)\n","    my_df = my_df.loc[:,~my_df.columns.duplicated()]\n","    return my_df\n","\n","def make_mi_scores(X, y):\n","    X = X.copy()\n","    for colname in X.select_dtypes([\"object\", \"category\"]):\n","        X[colname], _ = X[colname].factorize()\n","    # All discrete features should now have integer dtypes\n","    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n","    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n","    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n","    mi_scores = mi_scores.sort_values(ascending=False)\n","    return mi_scores\n","\n","def plot_mi_scores(scores):\n","    scores = scores.sort_values(ascending=True)\n","    width = np.arange(len(scores))\n","    ticks = list(scores.index)\n","    plt.barh(width, scores)\n","    plt.yticks(width, ticks)\n","    plt.title(\"Mutual Information Scores\")\n","\n","def drop_columns_missing_above_80_percent(train_df, test_df) -> None :\n","    null_series = train_df.isnull().sum().sort_values(ascending=False)\n","    print(\"columns have null values:\\n\", null_series, \"\\n\", sep=\"\")\n","    temp_lst = []\n","    for i,v in null_series.items():\n","        if v / train_df.shape[0] >= 0.8:\n","            temp_lst.append(i)\n","    train_df.drop(temp_lst, axis=1, inplace=True)\n","    null_series = train_df.isnull().sum().sort_values(ascending=False)\n","    print(\"after we drop the columns that miss 80 percent values:\\n\", null_series, sep=\"\")\n","\n","    null_series = test_df.isnull().sum().sort_values(ascending=False)\n","    print(\"columns have null values:\\n\", null_series, \"\\n\", sep=\"\")\n","    temp_lst = []\n","    for i,v in null_series.items():\n","        if v / test_df.shape[0] >= 0.8:\n","            temp_lst.append(i)\n","    test_df.drop(temp_lst, axis=1, inplace=True)\n","    null_series = test_df.isnull().sum().sort_values(ascending=False)\n","    print(\"after we drop the columns that miss 80 percent values:\\n\", null_series, sep=\"\")\n","\n","# Load Data.\n","train_df = pd.read_csv(\"input/train.csv\")\n","test_df = pd.read_csv(\"input/test.csv\")\n","# my_df = train_df.merge(test_df, how='outer')\n","\n","# Drop duplicates.\n","train_df = drop_duplicates(train_df)\n","test_df = drop_duplicates(test_df)\n","\n","# Handle missing values.\n","\n","# determine categorical and numerical features\n","numerical_ix = my_df.select_dtypes(include=['int64', 'float64']).columns\n","categorical_ix = my_df.select_dtypes(include=['object', 'bool']).columns\n","# define the data preparation for the columns\n","t = [('imputer_num', SimpleImputer(strategy='mean'), numerical_ix), ('imputer_cat', SimpleImputer(strategy='most_frequent'), categorical_ix), ('encoder', OneHotEncoder(), categorical_ix)]\n","\n","col_transform = ColumnTransformer(transformers=t, remainder=\"passthrough\")\n","my_df = col_transform.fit_transform(my_df)\n","my_df = pd.DataFrame(data=my_df)\n","my_df\n","# # define the model\n","# model = SVR(kernel='rbf',gamma='scale',C=100)\n","# # define the data preparation and modeling pipeline\n","# pipeline = Pipeline(steps=[('prep',col_transform), ('m', model)])\n","# # define the model cross-validation configuration\n","# cv = KFold(n_splits=10, shuffle=True, random_state=1)\n","# # evaluate the pipeline using cross validation and calculate MAE\n","# scores = cross_val_score(pipeline, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n","# # convert MAE scores to positive values\n","# scores = absolute(scores)\n","# # summarize the model performance\n","# print('MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n","\n","# Split dataset into training and testing sets.\n","\n","# Feature scaling (Optional). dataset into training and testing sets.\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["0       208500.0\n","1       181500.0\n","2       223500.0\n","3       140000.0\n","4       250000.0\n","          ...   \n","2914         NaN\n","2915         NaN\n","2916         NaN\n","2917         NaN\n","2918         NaN\n","Name: SalePrice, Length: 2919, dtype: float64\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>346</th>\n","      <th>347</th>\n","      <th>348</th>\n","      <th>349</th>\n","      <th>350</th>\n","      <th>351</th>\n","      <th>352</th>\n","      <th>353</th>\n","      <th>354</th>\n","      <th>355</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>60.0</td>\n","      <td>65.0</td>\n","      <td>8450.0</td>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>2003.0</td>\n","      <td>2003.0</td>\n","      <td>196.0</td>\n","      <td>706.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.0</td>\n","      <td>20.0</td>\n","      <td>80.0</td>\n","      <td>9600.0</td>\n","      <td>6.0</td>\n","      <td>8.0</td>\n","      <td>1976.0</td>\n","      <td>1976.0</td>\n","      <td>0.0</td>\n","      <td>978.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3.0</td>\n","      <td>60.0</td>\n","      <td>68.0</td>\n","      <td>11250.0</td>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>2001.0</td>\n","      <td>2002.0</td>\n","      <td>162.0</td>\n","      <td>486.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.0</td>\n","      <td>70.0</td>\n","      <td>60.0</td>\n","      <td>9550.0</td>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1915.0</td>\n","      <td>1970.0</td>\n","      <td>0.0</td>\n","      <td>216.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>60.0</td>\n","      <td>84.0</td>\n","      <td>14260.0</td>\n","      <td>8.0</td>\n","      <td>5.0</td>\n","      <td>2000.0</td>\n","      <td>2000.0</td>\n","      <td>350.0</td>\n","      <td>655.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2914</th>\n","      <td>2915.0</td>\n","      <td>160.0</td>\n","      <td>21.0</td>\n","      <td>1936.0</td>\n","      <td>4.0</td>\n","      <td>7.0</td>\n","      <td>1970.0</td>\n","      <td>1970.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2915</th>\n","      <td>2916.0</td>\n","      <td>160.0</td>\n","      <td>21.0</td>\n","      <td>1894.0</td>\n","      <td>4.0</td>\n","      <td>5.0</td>\n","      <td>1970.0</td>\n","      <td>1970.0</td>\n","      <td>0.0</td>\n","      <td>252.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2916</th>\n","      <td>2917.0</td>\n","      <td>20.0</td>\n","      <td>160.0</td>\n","      <td>20000.0</td>\n","      <td>5.0</td>\n","      <td>7.0</td>\n","      <td>1960.0</td>\n","      <td>1996.0</td>\n","      <td>0.0</td>\n","      <td>1224.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2917</th>\n","      <td>2918.0</td>\n","      <td>85.0</td>\n","      <td>62.0</td>\n","      <td>10441.0</td>\n","      <td>5.0</td>\n","      <td>5.0</td>\n","      <td>1992.0</td>\n","      <td>1992.0</td>\n","      <td>0.0</td>\n","      <td>337.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2918</th>\n","      <td>2919.0</td>\n","      <td>60.0</td>\n","      <td>74.0</td>\n","      <td>9627.0</td>\n","      <td>7.0</td>\n","      <td>5.0</td>\n","      <td>1993.0</td>\n","      <td>1994.0</td>\n","      <td>94.0</td>\n","      <td>758.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2919 rows Ã— 356 columns</p>\n","</div>"],"text/plain":["         0      1      2        3    4    5       6       7      8       9    \\\n","0        1.0   60.0   65.0   8450.0  7.0  5.0  2003.0  2003.0  196.0   706.0   \n","1        2.0   20.0   80.0   9600.0  6.0  8.0  1976.0  1976.0    0.0   978.0   \n","2        3.0   60.0   68.0  11250.0  7.0  5.0  2001.0  2002.0  162.0   486.0   \n","3        4.0   70.0   60.0   9550.0  7.0  5.0  1915.0  1970.0    0.0   216.0   \n","4        5.0   60.0   84.0  14260.0  8.0  5.0  2000.0  2000.0  350.0   655.0   \n","...      ...    ...    ...      ...  ...  ...     ...     ...    ...     ...   \n","2914  2915.0  160.0   21.0   1936.0  4.0  7.0  1970.0  1970.0    0.0     0.0   \n","2915  2916.0  160.0   21.0   1894.0  4.0  5.0  1970.0  1970.0    0.0   252.0   \n","2916  2917.0   20.0  160.0  20000.0  5.0  7.0  1960.0  1996.0    0.0  1224.0   \n","2917  2918.0   85.0   62.0  10441.0  5.0  5.0  1992.0  1992.0    0.0   337.0   \n","2918  2919.0   60.0   74.0   9627.0  7.0  5.0  1993.0  1994.0   94.0   758.0   \n","\n","      ...  346  347  348  349  350  351  352  353  354  355  \n","0     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n","1     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n","2     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n","3     ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n","4     ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n","...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n","2914  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n","2915  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n","2916  ...  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n","2917  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n","2918  ...  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n","\n","[2919 rows x 356 columns]"]},"metadata":{},"execution_count":17}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["fig, axs = plt.subplots(30, 3)\n","my_lst = [col for col in train_df.columns]\n","fig.set_size_inches(25, 200)\n","row = 30\n","col = 3\n","y = train_df[\"SalePrice\"]\n","for i in range(row):\n","    for j in range(col):\n","        if len(my_lst) == 0:\n","            break\n","        x = train_df[my_lst.pop()]\n","        axs[i, j].scatter(x, y)\n","        axs[i, j].set_xlabel(x.name)\n","        axs[i, j].set_ylabel(\"SalePrice\")\n","        axs[i, j].set_title(x.name + \" vs SalePrice\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["x_data = train_df[['LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea',\n","                    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n","                    'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n","                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]\n","y_data = train_df[\"SalePrice\"]\n","# my_train_lst = [col for col in train_df.columns]\n","# my_test_lst = [col for col in test_df.columns]\n","# my_train_lst.pop()\n","# my_test_lst.pop()\n","\n","# x_data = train_df[my_train_lst]\n","# test_data = test_df[my_test_lst]\n","test_data = test_df[ ['LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea',\n","                    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n","                    'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n","                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]\n","x_train, x_test, y_train, y_test = train_test_split(x_data, y_data)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# 5. Models building, evaluation, and predicting\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model = LinearRegression()\n","model2 = Lasso()\n","model3 = Ridge()\n","model4 = DecisionTreeRegressor()\n","model5 = RandomForestRegressor()\n","\n","model.fit(X=x_train, y=y_train)\n","model2.fit(X=x_train, y=y_train)\n","model3.fit(X=x_train, y=y_train)\n","model4.fit(X=x_train, y=y_train)\n","model5.fit(X=x_train, y=y_train)\n","\n","print(\"the accuracy score using with LinearRegression() model \", model.score(x_test, y_test))\n","print(\"the accuracy score using with Lasso() model \", model2.score(x_test, y_test))\n","print(\"the accuracy score using with Ridge() model \", model3.score(x_test, y_test))\n","print(\"the accuracy score using with DecisionTreeRegressor() model \", model4.score(x_test, y_test))\n","print(\"the accuracy score using with RandomForestRegressor() model \", model5.score(x_test, y_test))\n","\n","model.fit(X=x_train, y=y_train)\n","result = model.predict(test_data)\n","temp = test_df\n","temp.reset_index(inplace=True)\n","metric = pd.Series(result, name = 'SalePrice')\n","final_metric = pd.concat([temp[\"Id\"], metric], axis = 1)\n","final_metric.to_csv(\"submission.csv\",index =False)"],"outputs":[{"output_type":"stream","name":"stdout","text":["the accuracy score using with LinearRegression() model  0.699274404306837\n","the accuracy score using with Lasso() model  0.699255842859624\n","the accuracy score using with Ridge() model  0.6988298969020352\n","the accuracy score using with DecisionTreeRegressor() model  0.5258261751040558\n","the accuracy score using with RandomForestRegressor() model  0.647976119535729\n"]},{"output_type":"error","ename":"ValueError","evalue":"cannot insert level_0, already exists","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-39fc34f37b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfinal_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   5014\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5015\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5016\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5018\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3762\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3763\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"interpreter":{"hash":"470137a20ee2b1e4fecb351c4db86cc479a0f7d2037ff8b0353414b93267fdda"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}