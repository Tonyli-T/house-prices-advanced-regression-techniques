{"cells":[{"cell_type":"markdown","source":["Author Yizhou Li, e-mail: lyzpp2000@163.com"],"metadata":{}},{"cell_type":"markdown","source":["Problem Statement:"],"metadata":{}},{"cell_type":"markdown","source":["Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling<br>\n","or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences<br>\n","price negotiations than the number of bedrooms or a white-picket fence.<br>\n","<br>\n","With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition<br>\n","challenges you to predict the final price of each home."],"metadata":{}},{"cell_type":"markdown","source":["# 1. Data Preprocessing"],"metadata":{}},{"cell_type":"code","execution_count":53,"source":["# Step1: Loading necessary libraries and datasets.\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","\n","# Step2: Functions definitions.\n","def load_data():\n","    train_df = pd.read_csv(\"input/train.csv\")\n","    test_df = pd.read_csv(\"input/test.csv\")\n","    my_df = train_df.merge(test_df, how='outer')\n","    return my_df\n","\n","def drop_duplicates(my_df):\n","    my_df.drop_duplicates(inplace=True)\n","    my_df = my_df.loc[:,~my_df.columns.duplicated()]\n","    return my_df\n","\n","def make_mi_scores(X, y):\n","    X = X.copy()\n","    for colname in X.select_dtypes([\"object\", \"category\"]):\n","        X[colname], _ = X[colname].factorize()\n","    # All discrete features should now have integer dtypes\n","    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n","    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n","    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n","    mi_scores = mi_scores.sort_values(ascending=False)\n","    return mi_scores\n","\n","def plot_mi_scores(scores):\n","    scores = scores.sort_values(ascending=True)\n","    width = np.arange(len(scores))\n","    ticks = list(scores.index)\n","    plt.barh(width, scores)\n","    plt.yticks(width, ticks)\n","    plt.title(\"Mutual Information Scores\")\n","\n","def drop_columns_missing_above_80_percent(train_df, test_df) -> None :\n","    null_series = train_df.isnull().sum().sort_values(ascending=False)\n","    print(\"columns have null values:\\n\", null_series, \"\\n\", sep=\"\")\n","    temp_lst = []\n","    for i,v in null_series.items():\n","        if v / train_df.shape[0] >= 0.8:\n","            temp_lst.append(i)\n","    train_df.drop(temp_lst, axis=1, inplace=True)\n","    null_series = train_df.isnull().sum().sort_values(ascending=False)\n","    print(\"after we drop the columns that miss 80 percent values:\\n\", null_series, sep=\"\")\n","\n","    null_series = test_df.isnull().sum().sort_values(ascending=False)\n","    print(\"columns have null values:\\n\", null_series, \"\\n\", sep=\"\")\n","    temp_lst = []\n","    for i,v in null_series.items():\n","        if v / test_df.shape[0] >= 0.8:\n","            temp_lst.append(i)\n","    test_df.drop(temp_lst, axis=1, inplace=True)\n","    null_series = test_df.isnull().sum().sort_values(ascending=False)\n","    print(\"after we drop the columns that miss 80 percent values:\\n\", null_series, sep=\"\")\n","\n","# Step3: Load Data; Drop duplicates; Handle missing values.\n","my_df = load_data()\n","my_df = drop_duplicates(my_df)\n","\n","# todo \n","\n","# test\n","# d = {'col1': [1, np.nan, 2], 'col2': [np.nan, 4, 2]}\n","# df = pd.DataFrame(data=d)\n","\n","# imputer = SimpleImputer()\n","# d = imputer.fit_transform(df.select_dtypes(include=\"number\"))\n","# df = pd.DataFrame(data=d, columns=df.columns)\n","# df\n","# print(my_df['LotFrontage'].isnull().sum())\n","# print(my_df[\"LotFrontage\"].mean())\n","# my_df[\"LotFrontage\"].head(10)\n","# print(my_df.info())\n","\n","imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n","d = imputer.fit_transform(my_df.select_dtypes(include=\"number\"))\n","my_numerical_df = pd.DataFrame(data=d, columns=my_df.select_dtypes(include=\"number\").columns)\n","\n","imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n","d = imputer.fit_transform(my_df.select_dtypes(exclude=\"number\"))\n","my_categorical_df = pd.DataFrame(data=d, columns=my_df.select_dtypes(exclude=\"number\").columns)\n","\n","# my_df = my_numerical_df.merge(my_categorical_df, left_on=my_numerical_df.columns, right_on=my_categorical_df.columns)\n","# my_df.info()\n","\n","# Step4: Encode categorical values into numerical type.\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n","my_categorical_df = np.array(ct.fit_transform(my_categorical_df))\n","df = pd.DataFrame(data=my_categorical_df)\n","df\n","\n","# Step5: Split dataset into training and testing sets.\n","\n","# Step6: Feature scaling (Optional). dataset into training and testing sets.\n"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["       0    1    2    3    4     5     6    7    8       9   ...       37  \\\n","0     0.0  0.0  0.0  1.0  0.0  Pave  Grvl  Reg  Lvl  AllPub  ...   Attchd   \n","1     0.0  0.0  0.0  1.0  0.0  Pave  Grvl  Reg  Lvl  AllPub  ...   Attchd   \n","2     0.0  0.0  0.0  1.0  0.0  Pave  Grvl  IR1  Lvl  AllPub  ...   Attchd   \n","3     0.0  0.0  0.0  1.0  0.0  Pave  Grvl  IR1  Lvl  AllPub  ...   Detchd   \n","4     0.0  0.0  0.0  1.0  0.0  Pave  Grvl  IR1  Lvl  AllPub  ...   Attchd   \n","...   ...  ...  ...  ...  ...   ...   ...  ...  ...     ...  ...      ...   \n","2914  0.0  0.0  0.0  0.0  1.0  Pave  Grvl  Reg  Lvl  AllPub  ...   Attchd   \n","2915  0.0  0.0  0.0  0.0  1.0  Pave  Grvl  Reg  Lvl  AllPub  ...  CarPort   \n","2916  0.0  0.0  0.0  1.0  0.0  Pave  Grvl  Reg  Lvl  AllPub  ...   Detchd   \n","2917  0.0  0.0  0.0  1.0  0.0  Pave  Grvl  Reg  Lvl  AllPub  ...   Attchd   \n","2918  0.0  0.0  0.0  1.0  0.0  Pave  Grvl  Reg  Lvl  AllPub  ...   Attchd   \n","\n","       38  39  40 41  42     43    44  45       46  \n","0     RFn  TA  TA  Y  Ex  MnPrv  Shed  WD   Normal  \n","1     RFn  TA  TA  Y  Ex  MnPrv  Shed  WD   Normal  \n","2     RFn  TA  TA  Y  Ex  MnPrv  Shed  WD   Normal  \n","3     Unf  TA  TA  Y  Ex  MnPrv  Shed  WD  Abnorml  \n","4     RFn  TA  TA  Y  Ex  MnPrv  Shed  WD   Normal  \n","...   ...  ..  .. ..  ..    ...   ...  ..      ...  \n","2914  Unf  TA  TA  Y  Ex  MnPrv  Shed  WD   Normal  \n","2915  Unf  TA  TA  Y  Ex  MnPrv  Shed  WD  Abnorml  \n","2916  Unf  TA  TA  Y  Ex  MnPrv  Shed  WD  Abnorml  \n","2917  Unf  TA  TA  Y  Ex  MnPrv  Shed  WD   Normal  \n","2918  Fin  TA  TA  Y  Ex  MnPrv  Shed  WD   Normal  \n","\n","[2919 rows x 47 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>40</th>\n","      <th>41</th>\n","      <th>42</th>\n","      <th>43</th>\n","      <th>44</th>\n","      <th>45</th>\n","      <th>46</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Attchd</td>\n","      <td>RFn</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Attchd</td>\n","      <td>RFn</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Attchd</td>\n","      <td>RFn</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Detchd</td>\n","      <td>Unf</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Abnorml</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Attchd</td>\n","      <td>RFn</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2914</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Attchd</td>\n","      <td>Unf</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>2915</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>CarPort</td>\n","      <td>Unf</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Abnorml</td>\n","    </tr>\n","    <tr>\n","      <th>2916</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Detchd</td>\n","      <td>Unf</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Abnorml</td>\n","    </tr>\n","    <tr>\n","      <th>2917</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Attchd</td>\n","      <td>Unf</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","    </tr>\n","    <tr>\n","      <th>2918</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>Pave</td>\n","      <td>Grvl</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>Attchd</td>\n","      <td>Fin</td>\n","      <td>TA</td>\n","      <td>TA</td>\n","      <td>Y</td>\n","      <td>Ex</td>\n","      <td>MnPrv</td>\n","      <td>Shed</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2919 rows × 47 columns</p>\n","</div>"]},"metadata":{},"execution_count":53}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["fig, axs = plt.subplots(30, 3)\n","my_lst = [col for col in train_df.columns]\n","fig.set_size_inches(25, 200)\n","row = 30\n","col = 3\n","y = train_df[\"SalePrice\"]\n","for i in range(row):\n","    for j in range(col):\n","        if len(my_lst) == 0:\n","            break\n","        x = train_df[my_lst.pop()]\n","        axs[i, j].scatter(x, y)\n","        axs[i, j].set_xlabel(x.name)\n","        axs[i, j].set_ylabel(\"SalePrice\")\n","        axs[i, j].set_title(x.name + \" vs SalePrice\")"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["x_data = train_df[['LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea',\n","                    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n","                    'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n","                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]\n","y_data = train_df[\"SalePrice\"]\n","# my_train_lst = [col for col in train_df.columns]\n","# my_test_lst = [col for col in test_df.columns]\n","# my_train_lst.pop()\n","# my_test_lst.pop()\n","\n","# x_data = train_df[my_train_lst]\n","# test_data = test_df[my_test_lst]\n","test_data = test_df[ ['LotFrontage', 'LotArea', 'MasVnrArea', 'TotalBsmtSF', 'GrLivArea',\n","                    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n","                    'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n","                    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal']]\n","x_train, x_test, y_train, y_test = train_test_split(x_data, y_data)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# 5. Models building, evaluation, and predicting\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["model = LinearRegression()\n","model2 = Lasso()\n","model3 = Ridge()\n","model4 = DecisionTreeRegressor()\n","model5 = RandomForestRegressor()\n","\n","model.fit(X=x_train, y=y_train)\n","model2.fit(X=x_train, y=y_train)\n","model3.fit(X=x_train, y=y_train)\n","model4.fit(X=x_train, y=y_train)\n","model5.fit(X=x_train, y=y_train)\n","\n","print(\"the accuracy score using with LinearRegression() model \", model.score(x_test, y_test))\n","print(\"the accuracy score using with Lasso() model \", model2.score(x_test, y_test))\n","print(\"the accuracy score using with Ridge() model \", model3.score(x_test, y_test))\n","print(\"the accuracy score using with DecisionTreeRegressor() model \", model4.score(x_test, y_test))\n","print(\"the accuracy score using with RandomForestRegressor() model \", model5.score(x_test, y_test))\n","\n","model.fit(X=x_train, y=y_train)\n","result = model.predict(test_data)\n","temp = test_df\n","temp.reset_index(inplace=True)\n","metric = pd.Series(result, name = 'SalePrice')\n","final_metric = pd.concat([temp[\"Id\"], metric], axis = 1)\n","final_metric.to_csv(\"submission.csv\",index =False)"],"outputs":[{"output_type":"stream","name":"stdout","text":["the accuracy score using with LinearRegression() model  0.699274404306837\n","the accuracy score using with Lasso() model  0.699255842859624\n","the accuracy score using with Ridge() model  0.6988298969020352\n","the accuracy score using with DecisionTreeRegressor() model  0.5258261751040558\n","the accuracy score using with RandomForestRegressor() model  0.647976119535729\n"]},{"output_type":"error","ename":"ValueError","evalue":"cannot insert level_0, already exists","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-39fc34f37b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mfinal_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   5014\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5015\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5016\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5018\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3762\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3763\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3765\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"interpreter":{"hash":"470137a20ee2b1e4fecb351c4db86cc479a0f7d2037ff8b0353414b93267fdda"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}